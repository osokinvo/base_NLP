{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Подготовка набора данных и функций<h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Импортируем библиотки<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Подготовка данных<h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Посмотрим какие файлы находятся в папке \"data\"<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mp00_tweets.zip\u001b[0m*         \u001b[01;32mprocessedNeutral.csv\u001b[0m*\n",
      "\u001b[01;32mprocessedNegative.csv\u001b[0m*  \u001b[01;32mprocessedPositive.csv\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>В качестве примера рассмотрим содержимое файла 'processedNegative.csv'<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>How unhappy  some dogs like it though</th>\n",
       "      <th>talking to my over driver about where I'm goinghe said he'd love to go to New York too but since Trump it's probably not</th>\n",
       "      <th>Does anybody know if the Rand's likely to fall against the dollar? I got some money  I need to change into R but it keeps getting stronger unhappy</th>\n",
       "      <th>I miss going to gigs in Liverpool unhappy</th>\n",
       "      <th>There isnt a new Riverdale tonight ? unhappy</th>\n",
       "      <th>it's that A*dy guy from pop Asia and then the translator so they'll probs go with them around Aus unhappy</th>\n",
       "      <th>Who's that chair you're sitting in? Is this how I find out. Everyone knows now. You've shamed me in pu</th>\n",
       "      <th>don't like how jittery caffeine makes me sad</th>\n",
       "      <th>My area's not on the list unhappy  think I'll go LibDems anyway</th>\n",
       "      <th>I want fun plans this weekend unhappy</th>\n",
       "      <th>...</th>\n",
       "      <th>and yet if parents invest in child's emotional education by taking child out of school on holiday early that's un</th>\n",
       "      <th>YG should have sent them to MCD. I want to see them holding the trophy unhappy  anyways .9</th>\n",
       "      <th>i want more orientation unhappy</th>\n",
       "      <th>unhappy  they not</th>\n",
       "      <th>YG should have sent them to MCD. I want to see them holding the trophy unhappy  anyways .10</th>\n",
       "      <th>wish knock out lang talaga for the new school year are good and cooperative groupmates please unhappy</th>\n",
       "      <th>i miss so much unhappy</th>\n",
       "      <th>Same unhappy .1</th>\n",
       "      <th>Hi instant message your friend  friend lang</th>\n",
       "      <th>hindi close friend? unhappy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [How unhappy  some dogs like it though, talking to my over driver about where I'm goinghe said he'd love to go to New York too but since Trump it's probably not, Does anybody know if the Rand's likely to fall against the dollar? I got some money  I need to change into R but it keeps getting stronger unhappy , I miss going to gigs in Liverpool unhappy , There isnt a new Riverdale tonight ? unhappy , it's that A*dy guy from pop Asia and then the translator so they'll probs go with them around Aus unhappy , Who's that chair you're sitting in? Is this how I find out. Everyone knows now. You've shamed me in pu, don't like how jittery caffeine makes me sad , My area's not on the list unhappy  think I'll go LibDems anyway, I want fun plans this weekend unhappy , When can you notice me.  unhappy  what?  , Ahhhhh! You recognized LOGAN!!! Cinemax shows have a BAD track record for getting cancelled unhappy , Errr dude.... They're gone unhappy  Asked other league memeber to check  the guys are go , Not you again sad  , Why would Harvey be going to prison? unhappy , Missing in crying  Seaside area. , Becoz if we will depend on your promoting its waste of hardwork to all team who , I thought you'll save me crying , major waffle cravings right now sad , cant speak japanese ::(, how can people do stuff like this unhappy  , please just stop confining animals in zoos unhappy  , Feel like i shoyould be telling you to get the fuck out social media byout also feel really mean because unhappy  silence  love yoyou hope yoyoure okay , i miss you huhu so busy unhappy , it was extended family. 12 ppl.ahh wanted to show a Oh My Girl being dorky while playing a game but it got deleted unhappy , Don't do that unhappy , Jamie can you please reset the CGa grandfinal server... no administrator are responding unhappy , noOoooooo YOU GONNA MISS THE BUFFET unhappy  TAKE CARE AIN!!!!!!!!!!!!!!!!! , I wish i could vote for you unhappy , instant message so jealous okay unhappy  but never mind haha bruno can wait finals first, when i'm enlisting can please turn up like this unhappy  , unhappy  how come people like this have children where's the state intervention , Ouchhhhh unhappy  , Help... I want to stop tweeting. All I feel is endless suffering and pain. I tried to deactivate myself many times... Save me... unhappy , For those asking,  the application is Kana Kanji Funtime! Sadly,  it looks like iOS 11 is due to kill it unhappy  , Yeah did update to 16.04 ,  it froze a few times. Then went to 16.10,  froze mid install. Waited 3hrs he'd to pull plug crying , Shaandaar,  Zabardast,  Another ATBB on it's way ! I wish Srk Sir starts signing good movies unhappy  , I want Jabee crying , sociopath full raid gear sad  , When will you say hi sunshine ? unhappy  , i feel bad for doing that AHAHA unhappy , it's getting harder and harder to stay unhappy , His face looks bloated unhappy  baby get well soon , fuck. tried changing my settings but still in india. unhappy , talking to my over driver about where I'm goinghe said he'd love to go to New York too but since Trump it's probably not.1, Let's not forget that it's also Gabriel Tenma White's birthday today!I miss unhappy  , Why am i always taken for granted eversince unhappy , Ah alright,  i don%27t know if you saw my comment yet,  but what camera you shooting with,  does it have flip out scr , I miss Louis' tweets unhappy , Koalas are dying of thirst  and it's all because of us unhappy  , okay I'll shut up now. instant message just mad that lots of people will now have a VERY flawed opinion on mental health ( on mine) because of this show unhappy , pamura isa because in this very moment,  i want to explode like a grenade to the point where people will die with me. sad , YG should have sent them to MCD. I want to see them holding the trophy unhappy  anyways , i really want one of those iconic jimin stripes turtleneck shirt unhappy , I want a spoons but I cant go unhappy  honestly feels like a messy break up unhappy , Makes me so sad unhappy  they looked so unhappy when I went to SeaWorld , YG should have sent them to MCD. I want to see them holding the trophy unhappy  anyways .1, I miss Rockys posts unhappy  , Hey Tony,  oh no unhappy  Could you please tell me a little more about your issue? Im following if youd prefer to DM. Amanda, i love mason and miss mason unhappy , Cold as a mother crusher right now. Nearing the end of April. sad , we don%27t talk anymore like we used to do unhappy , YG should have sent them to MCD. I want to see them holding the trophy unhappy  anyways .2, miss biking unhappy , I miss Big brother unhappy , 6 days in camp haiss miss you a lot unhappy , It's raining so hard unhappy , Am bored and kandowiandg I have ando plaands for today is makiandg me eveand more bored unhappy , oh my god not laurie penny unhappy , can you say Hi Mekisha? unhappy , I should never draw again unhappy , Cleantha , Visual Studio Installation - 89% .. BSOD comes suddenly unhappy , i want to make waffles unhappy , So sad unhappy  , crying  muh feels, Look like somethings i will ignore xD Kart Racing when? unhappy , did ate jenna just blocked me or what? unhappy , My bed is so comfortable I don't want to get up unhappy , Is that store still in use? If so,  I sincerely hope not too many priceless antiques were destroyed. Reg , Astaga unhappy  /? , I want a puppy now unhappy , have to work unhappy  but i'll see you tomorrow!! , happy weed day without them is not the same anymore unhappy , my favourite lipstick hilang crying , Time just flies,  can't believe he will be year for next year unhappy  We're becoming old HAHAHAH :v, The new Twitter reply view has me confused... like do I capitalise my replies to people or not? unhappy , ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1117 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df = pd.read_csv('data/processedNegative.csv')\n",
    "neg_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Видно, что tweets находятся все в одной строке, что является не удобным<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How unhappy  some dogs like it though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talking to my over driver about where I'm goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does anybody know if the Rand's likely to fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I miss going to gigs in Liverpool unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There isnt a new Riverdale tonight ? unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>wish knock out lang talaga for the new school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>i miss so much unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Same unhappy .1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>Hi instant message your friend  friend lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>hindi close friend? unhappy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index\n",
       "0                 How unhappy  some dogs like it though\n",
       "1     talking to my over driver about where I'm goin...\n",
       "2     Does anybody know if the Rand's likely to fall...\n",
       "3            I miss going to gigs in Liverpool unhappy \n",
       "4         There isnt a new Riverdale tonight ? unhappy \n",
       "...                                                 ...\n",
       "1112  wish knock out lang talaga for the new school ...\n",
       "1113                            i miss so much unhappy \n",
       "1114                                    Same unhappy .1\n",
       "1115        Hi instant message your friend  friend lang\n",
       "1116                        hindi close friend? unhappy\n",
       "\n",
       "[1117 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_neg_df = neg_df.T\n",
    "new_neg_df.reset_index(inplace=True)\n",
    "new_neg_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Посмотрим информацию об объектах набора данных<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1117 entries, 0 to 1116\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   1117 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "new_neg_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Информация показывает, что объектов Nan нет<h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Для дальнейшей работы методы этого проекта предполагают получение предложения. Создадим переменную text с содержанием всех строк набора данных<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How unhappy  some dogs like it though talking to my over driver about where I'm goinghe said he'd love to go to New York too but since Trump it's probably not Does anybody know if the Rand's likely to fall against the dollar? I got some money  I need to change into R but it keeps getting stronger un\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join([tweet[0] for tweet in new_neg_df.values.tolist()])\n",
    "text[:300]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Используемые функции<h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>В дальнейшем для уменьшения размера текста кода будут использоваться функции, Первый этап включает перечисленную выше обработку данных, обработку данных метода и создание набора для обучения. Рассмотрим этапы создания наборов для обучения.\n",
    "Будем предполагать, что получаем несколько словарей, где ключом будут слова, а значениями ключей количество этих слов в наборе данных.<h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Создадим словарь<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'How': 3,\n",
       "         'unhappy': 781,\n",
       "         '': 1367,\n",
       "         'some': 15,\n",
       "         'dogs': 4,\n",
       "         'like': 47,\n",
       "         'it': 89,\n",
       "         'though': 6,\n",
       "         'talking': 12,\n",
       "         'to': 304,\n",
       "         'my': 132,\n",
       "         'over': 14,\n",
       "         'driver': 9,\n",
       "         'about': 32,\n",
       "         'where': 14,\n",
       "         \"I'm\": 55,\n",
       "         'goinghe': 9,\n",
       "         'said': 14,\n",
       "         \"he'd\": 10,\n",
       "         'love': 38,\n",
       "         'go': 24,\n",
       "         'New': 9,\n",
       "         'York': 9,\n",
       "         'too': 33,\n",
       "         'but': 102,\n",
       "         'since': 22,\n",
       "         'Trump': 9,\n",
       "         \"it's\": 54,\n",
       "         'probably': 10,\n",
       "         'not': 57,\n",
       "         'Does': 2,\n",
       "         'anybody': 1,\n",
       "         'know': 13,\n",
       "         'if': 26,\n",
       "         'the': 192,\n",
       "         \"Rand's\": 1,\n",
       "         'likely': 1,\n",
       "         'fall': 3,\n",
       "         'against': 1,\n",
       "         'dollar?': 1,\n",
       "         'I': 281,\n",
       "         'got': 20,\n",
       "         'money': 1,\n",
       "         'need': 17,\n",
       "         'change': 1,\n",
       "         'into': 3,\n",
       "         'R': 1,\n",
       "         'keeps': 2,\n",
       "         'getting': 14,\n",
       "         'stronger': 1,\n",
       "         'miss': 61,\n",
       "         'going': 23,\n",
       "         'gigs': 1,\n",
       "         'in': 88,\n",
       "         'Liverpool': 1,\n",
       "         'There': 1,\n",
       "         'isnt': 1,\n",
       "         'a': 145,\n",
       "         'new': 4,\n",
       "         'Riverdale': 1,\n",
       "         'tonight': 4,\n",
       "         '?': 6,\n",
       "         'that': 45,\n",
       "         'A*dy': 1,\n",
       "         'guy': 1,\n",
       "         'from': 9,\n",
       "         'pop': 1,\n",
       "         'Asia': 1,\n",
       "         'and': 142,\n",
       "         'then': 6,\n",
       "         'translator': 1,\n",
       "         'so': 100,\n",
       "         \"they'll\": 2,\n",
       "         'probs': 1,\n",
       "         'with': 40,\n",
       "         'them': 55,\n",
       "         'around': 4,\n",
       "         'Aus': 1,\n",
       "         \"Who's\": 1,\n",
       "         'chair': 1,\n",
       "         \"you're\": 10,\n",
       "         'sitting': 2,\n",
       "         'in?': 1,\n",
       "         'Is': 3,\n",
       "         'this': 78,\n",
       "         'how': 25,\n",
       "         'find': 6,\n",
       "         'out.': 1,\n",
       "         'Everyone': 1,\n",
       "         'knows': 3,\n",
       "         'now.': 3,\n",
       "         \"You've\": 1,\n",
       "         'shamed': 1,\n",
       "         'me': 87,\n",
       "         'pu': 1,\n",
       "         \"don't\": 31,\n",
       "         'jittery': 1,\n",
       "         'caffeine': 2,\n",
       "         'makes': 7,\n",
       "         'sad': 71,\n",
       "         'My': 18,\n",
       "         \"area's\": 1,\n",
       "         'on': 52,\n",
       "         'list': 1,\n",
       "         'think': 10,\n",
       "         \"I'll\": 11,\n",
       "         'LibDems': 1,\n",
       "         'anyway': 4,\n",
       "         'want': 78,\n",
       "         'fun': 24,\n",
       "         'plans': 3,\n",
       "         'weekend': 2,\n",
       "         'When': 15,\n",
       "         'can': 22,\n",
       "         'you': 129,\n",
       "         'notice': 8,\n",
       "         'me.': 5,\n",
       "         'what?': 3,\n",
       "         'Ahhhhh!': 1,\n",
       "         'You': 10,\n",
       "         'recognized': 1,\n",
       "         'LOGAN!!!': 1,\n",
       "         'Cinemax': 1,\n",
       "         'shows': 1,\n",
       "         'have': 66,\n",
       "         'BAD': 1,\n",
       "         'track': 1,\n",
       "         'record': 1,\n",
       "         'for': 83,\n",
       "         'cancelled': 1,\n",
       "         'Errr': 1,\n",
       "         'dude....': 1,\n",
       "         \"They're\": 1,\n",
       "         'gone': 4,\n",
       "         'Asked': 1,\n",
       "         'other': 7,\n",
       "         'league': 1,\n",
       "         'memeber': 1,\n",
       "         'check': 3,\n",
       "         'guys': 8,\n",
       "         'are': 55,\n",
       "         'Not': 6,\n",
       "         'again': 6,\n",
       "         'Why': 7,\n",
       "         'would': 12,\n",
       "         'Harvey': 1,\n",
       "         'be': 58,\n",
       "         'prison?': 1,\n",
       "         'Missing': 1,\n",
       "         'crying': 42,\n",
       "         'Seaside': 1,\n",
       "         'area.': 1,\n",
       "         'Becoz': 1,\n",
       "         'we': 24,\n",
       "         'will': 21,\n",
       "         'depend': 1,\n",
       "         'your': 48,\n",
       "         'promoting': 1,\n",
       "         'its': 11,\n",
       "         'waste': 1,\n",
       "         'of': 137,\n",
       "         'hardwork': 1,\n",
       "         'all': 50,\n",
       "         'team': 2,\n",
       "         'who': 44,\n",
       "         'thought': 3,\n",
       "         \"you'll\": 2,\n",
       "         'save': 2,\n",
       "         'major': 1,\n",
       "         'waffle': 1,\n",
       "         'cravings': 1,\n",
       "         'right': 12,\n",
       "         'now': 25,\n",
       "         'cant': 10,\n",
       "         'speak': 1,\n",
       "         'japanese': 1,\n",
       "         '::(': 1,\n",
       "         'people': 59,\n",
       "         'do': 27,\n",
       "         'stuff': 3,\n",
       "         'please': 29,\n",
       "         'just': 46,\n",
       "         'stop': 4,\n",
       "         'confining': 1,\n",
       "         'animals': 3,\n",
       "         'zoos': 1,\n",
       "         'Feel': 3,\n",
       "         'i': 147,\n",
       "         'shoyould': 1,\n",
       "         'telling': 2,\n",
       "         'get': 37,\n",
       "         'fuck': 8,\n",
       "         'out': 18,\n",
       "         'social': 2,\n",
       "         'media': 2,\n",
       "         'byout': 1,\n",
       "         'also': 3,\n",
       "         'feel': 14,\n",
       "         'really': 31,\n",
       "         'mean': 4,\n",
       "         'because': 35,\n",
       "         'silence': 3,\n",
       "         'yoyou': 4,\n",
       "         'hope': 16,\n",
       "         'yoyoure': 1,\n",
       "         'okay': 9,\n",
       "         'huhu': 3,\n",
       "         'busy': 1,\n",
       "         'was': 36,\n",
       "         'extended': 1,\n",
       "         'family.': 2,\n",
       "         '12': 2,\n",
       "         'ppl.ahh': 1,\n",
       "         'wanted': 2,\n",
       "         'show': 4,\n",
       "         'Oh': 8,\n",
       "         'Girl': 1,\n",
       "         'being': 7,\n",
       "         'dorky': 1,\n",
       "         'while': 5,\n",
       "         'playing': 2,\n",
       "         'game': 5,\n",
       "         'deleted': 1,\n",
       "         \"Don't\": 6,\n",
       "         'Jamie': 2,\n",
       "         'reset': 1,\n",
       "         'CGa': 1,\n",
       "         'grandfinal': 1,\n",
       "         'server...': 1,\n",
       "         'no': 31,\n",
       "         'administrator': 1,\n",
       "         'responding': 1,\n",
       "         'noOoooooo': 1,\n",
       "         'YOU': 6,\n",
       "         'GONNA': 1,\n",
       "         'MISS': 4,\n",
       "         'THE': 3,\n",
       "         'BUFFET': 1,\n",
       "         'TAKE': 1,\n",
       "         'CARE': 1,\n",
       "         'AIN!!!!!!!!!!!!!!!!!': 1,\n",
       "         'wish': 18,\n",
       "         'could': 12,\n",
       "         'vote': 2,\n",
       "         'instant': 14,\n",
       "         'message': 15,\n",
       "         'jealous': 3,\n",
       "         'never': 14,\n",
       "         'mind': 2,\n",
       "         'haha': 3,\n",
       "         'bruno': 1,\n",
       "         'wait': 3,\n",
       "         'finals': 1,\n",
       "         'first': 1,\n",
       "         'when': 29,\n",
       "         \"i'm\": 10,\n",
       "         'enlisting': 1,\n",
       "         'turn': 1,\n",
       "         'up': 29,\n",
       "         'come': 9,\n",
       "         'children': 2,\n",
       "         \"where's\": 2,\n",
       "         'state': 1,\n",
       "         'intervention': 1,\n",
       "         'Ouchhhhh': 1,\n",
       "         'Help...': 1,\n",
       "         'tweeting.': 1,\n",
       "         'All': 6,\n",
       "         'is': 109,\n",
       "         'endless': 1,\n",
       "         'suffering': 2,\n",
       "         'pain.': 2,\n",
       "         'tried': 10,\n",
       "         'deactivate': 2,\n",
       "         'myself': 2,\n",
       "         'many': 7,\n",
       "         'times...': 1,\n",
       "         'Save': 1,\n",
       "         'me...': 1,\n",
       "         'For': 2,\n",
       "         'those': 23,\n",
       "         'asking': 1,\n",
       "         'application': 1,\n",
       "         'Kana': 1,\n",
       "         'Kanji': 1,\n",
       "         'Funtime!': 1,\n",
       "         'Sadly': 1,\n",
       "         'looks': 6,\n",
       "         'iOS': 1,\n",
       "         '11': 2,\n",
       "         'due': 2,\n",
       "         'kill': 2,\n",
       "         'Yeah': 2,\n",
       "         'did': 13,\n",
       "         'update': 3,\n",
       "         '16.04': 1,\n",
       "         'froze': 2,\n",
       "         'few': 6,\n",
       "         'times.': 1,\n",
       "         'Then': 1,\n",
       "         'went': 5,\n",
       "         '16.10': 1,\n",
       "         'mid': 1,\n",
       "         'install.': 1,\n",
       "         'Waited': 1,\n",
       "         '3hrs': 1,\n",
       "         'pull': 1,\n",
       "         'plug': 1,\n",
       "         'Shaandaar': 1,\n",
       "         'Zabardast': 1,\n",
       "         'Another': 1,\n",
       "         'ATBB': 1,\n",
       "         'way': 6,\n",
       "         '!': 4,\n",
       "         'Srk': 1,\n",
       "         'Sir': 2,\n",
       "         'starts': 2,\n",
       "         'signing': 1,\n",
       "         'good': 18,\n",
       "         'movies': 1,\n",
       "         'Jabee': 1,\n",
       "         'sociopath': 1,\n",
       "         'full': 5,\n",
       "         'raid': 1,\n",
       "         'gear': 1,\n",
       "         'say': 12,\n",
       "         'hi': 2,\n",
       "         'sunshine': 1,\n",
       "         'bad': 8,\n",
       "         'doing': 2,\n",
       "         'AHAHA': 1,\n",
       "         'harder': 2,\n",
       "         'stay': 4,\n",
       "         'His': 1,\n",
       "         'face': 8,\n",
       "         'bloated': 1,\n",
       "         'baby': 14,\n",
       "         'well': 8,\n",
       "         'soon': 10,\n",
       "         'fuck.': 1,\n",
       "         'changing': 1,\n",
       "         'settings': 1,\n",
       "         'still': 18,\n",
       "         'india.': 1,\n",
       "         'not.1': 1,\n",
       "         \"Let's\": 2,\n",
       "         'forget': 2,\n",
       "         'Gabriel': 1,\n",
       "         'Tenma': 1,\n",
       "         \"White's\": 1,\n",
       "         'birthday': 24,\n",
       "         'today!I': 1,\n",
       "         'am': 12,\n",
       "         'always': 8,\n",
       "         'taken': 2,\n",
       "         'granted': 1,\n",
       "         'eversince': 1,\n",
       "         'Ah': 2,\n",
       "         'alright': 1,\n",
       "         'don%27t': 14,\n",
       "         'saw': 2,\n",
       "         'comment': 1,\n",
       "         'yet': 7,\n",
       "         'what': 23,\n",
       "         'camera': 1,\n",
       "         'shooting': 1,\n",
       "         'does': 5,\n",
       "         'flip': 1,\n",
       "         'scr': 1,\n",
       "         \"Louis'\": 1,\n",
       "         'tweets': 2,\n",
       "         'Koalas': 15,\n",
       "         'dying': 18,\n",
       "         'thirst': 17,\n",
       "         'us': 24,\n",
       "         'shut': 2,\n",
       "         'mad': 3,\n",
       "         'lots': 2,\n",
       "         'VERY': 1,\n",
       "         'flawed': 1,\n",
       "         'opinion': 1,\n",
       "         'mental': 1,\n",
       "         'health': 1,\n",
       "         '(': 4,\n",
       "         'mine)': 1,\n",
       "         'pamura': 1,\n",
       "         'isa': 1,\n",
       "         'very': 6,\n",
       "         'moment': 1,\n",
       "         'explode': 1,\n",
       "         'grenade': 1,\n",
       "         'point': 1,\n",
       "         'die': 1,\n",
       "         'YG': 11,\n",
       "         'should': 18,\n",
       "         'sent': 11,\n",
       "         'MCD.': 11,\n",
       "         'see': 35,\n",
       "         'holding': 11,\n",
       "         'trophy': 11,\n",
       "         'anyways': 11,\n",
       "         'one': 24,\n",
       "         'iconic': 1,\n",
       "         'jimin': 10,\n",
       "         'stripes': 1,\n",
       "         'turtleneck': 1,\n",
       "         'shirt': 2,\n",
       "         'spoons': 1,\n",
       "         'honestly': 3,\n",
       "         'feels': 5,\n",
       "         'messy': 1,\n",
       "         'break': 2,\n",
       "         'Makes': 1,\n",
       "         'they': 22,\n",
       "         'looked': 4,\n",
       "         'SeaWorld': 1,\n",
       "         '.1': 42,\n",
       "         'Rockys': 1,\n",
       "         'posts': 2,\n",
       "         'Hey': 3,\n",
       "         'Tony': 1,\n",
       "         'oh': 12,\n",
       "         'Could': 2,\n",
       "         'tell': 5,\n",
       "         'little': 8,\n",
       "         'more': 17,\n",
       "         'issue?': 1,\n",
       "         'Im': 4,\n",
       "         'following': 1,\n",
       "         'youd': 1,\n",
       "         'prefer': 1,\n",
       "         'DM.': 1,\n",
       "         'Amanda': 1,\n",
       "         'mason': 2,\n",
       "         'Cold': 1,\n",
       "         'as': 12,\n",
       "         'mother': 1,\n",
       "         'crusher': 1,\n",
       "         'Nearing': 1,\n",
       "         'end': 2,\n",
       "         'April.': 1,\n",
       "         'talk': 5,\n",
       "         'anymore': 6,\n",
       "         'used': 3,\n",
       "         '.2': 14,\n",
       "         'biking': 1,\n",
       "         'Big': 1,\n",
       "         'brother': 1,\n",
       "         '6': 1,\n",
       "         'days': 9,\n",
       "         'camp': 3,\n",
       "         'haiss': 1,\n",
       "         'lot': 5,\n",
       "         \"It's\": 10,\n",
       "         'raining': 1,\n",
       "         'hard': 5,\n",
       "         'Am': 2,\n",
       "         'bored': 5,\n",
       "         'kandowiandg': 1,\n",
       "         'ando': 2,\n",
       "         'plaands': 1,\n",
       "         'today': 21,\n",
       "         'makiandg': 1,\n",
       "         'eveand': 1,\n",
       "         'god': 6,\n",
       "         'laurie': 1,\n",
       "         'penny': 1,\n",
       "         'Hi': 10,\n",
       "         'Mekisha?': 1,\n",
       "         'draw': 3,\n",
       "         'Cleantha': 1,\n",
       "         'Visual': 1,\n",
       "         'Studio': 1,\n",
       "         'Installation': 1,\n",
       "         '-': 14,\n",
       "         '89%': 1,\n",
       "         '..': 4,\n",
       "         'BSOD': 1,\n",
       "         'comes': 6,\n",
       "         'suddenly': 2,\n",
       "         'make': 29,\n",
       "         'waffles': 1,\n",
       "         'So': 7,\n",
       "         'muh': 1,\n",
       "         'Look': 1,\n",
       "         'somethings': 1,\n",
       "         'ignore': 1,\n",
       "         'xD': 1,\n",
       "         'Kart': 1,\n",
       "         'Racing': 1,\n",
       "         'when?': 1,\n",
       "         'ate': 4,\n",
       "         'jenna': 1,\n",
       "         'blocked': 1,\n",
       "         'or': 12,\n",
       "         'bed': 3,\n",
       "         'comfortable': 1,\n",
       "         'store': 1,\n",
       "         'use?': 1,\n",
       "         'If': 4,\n",
       "         'sincerely': 18,\n",
       "         'priceless': 1,\n",
       "         'antiques': 1,\n",
       "         'were': 13,\n",
       "         'destroyed.': 1,\n",
       "         'Reg': 1,\n",
       "         'Astaga': 1,\n",
       "         '/?': 1,\n",
       "         'puppy': 1,\n",
       "         'work': 14,\n",
       "         \"i'll\": 6,\n",
       "         'tomorrow!!': 1,\n",
       "         'happy': 7,\n",
       "         'weed': 1,\n",
       "         'day': 15,\n",
       "         'without': 6,\n",
       "         'same': 6,\n",
       "         'favourite': 1,\n",
       "         'lipstick': 1,\n",
       "         'hilang': 1,\n",
       "         'Time': 1,\n",
       "         'flies': 1,\n",
       "         \"can't\": 25,\n",
       "         'believe': 4,\n",
       "         'he': 22,\n",
       "         'year': 9,\n",
       "         'next': 8,\n",
       "         \"We're\": 4,\n",
       "         'becoming': 1,\n",
       "         'old': 6,\n",
       "         'HAHAHAH': 1,\n",
       "         ':v': 1,\n",
       "         'The': 8,\n",
       "         'Twitter': 1,\n",
       "         'reply': 2,\n",
       "         'view': 2,\n",
       "         'has': 17,\n",
       "         'confused...': 1,\n",
       "         'capitalise': 1,\n",
       "         'replies': 1,\n",
       "         'not?': 1,\n",
       "         'Whaddup.': 1,\n",
       "         'Me': 5,\n",
       "         'every': 3,\n",
       "         'time': 24,\n",
       "         'laughing': 3,\n",
       "         'ass': 4,\n",
       "         'off': 13,\n",
       "         \"who's\": 5,\n",
       "         'selling': 2,\n",
       "         'an': 13,\n",
       "         'army': 1,\n",
       "         'bomb': 1,\n",
       "         'ver': 1,\n",
       "         '2???': 1,\n",
       "         'meet': 4,\n",
       "         'Yeesh': 1,\n",
       "         'fairly': 1,\n",
       "         'warm': 2,\n",
       "         'here.': 1,\n",
       "         'easter': 2,\n",
       "         'flown': 1,\n",
       "         'ready': 4,\n",
       "         'give': 7,\n",
       "         'home': 3,\n",
       "         'luxuries': 1,\n",
       "         'branded': 1,\n",
       "         'cereal': 1,\n",
       "         'Ohnoo': 1,\n",
       "         'recuperates': 1,\n",
       "         'sooner!!': 1,\n",
       "         'Her': 5,\n",
       "         'back': 19,\n",
       "         'chance': 4,\n",
       "         'west': 1,\n",
       "         'server': 1,\n",
       "         'yesterday': 5,\n",
       "         'agree.': 1,\n",
       "         'issue': 2,\n",
       "         'paid': 1,\n",
       "         'somehow.': 1,\n",
       "         'numbers': 3,\n",
       "         'adding': 1,\n",
       "         'up.': 3,\n",
       "         'drink': 5,\n",
       "         'cigarettes': 1,\n",
       "         'mince': 1,\n",
       "         'manifesto': 1,\n",
       "         'Nick?': 1,\n",
       "         'Might': 1,\n",
       "         'deliver': 1,\n",
       "         'WHEN': 2,\n",
       "         'demands': 1,\n",
       "         'it.': 3,\n",
       "         'Story': 1,\n",
       "         'his': 10,\n",
       "         'life': 7,\n",
       "         \"I've\": 6,\n",
       "         'accepted': 1,\n",
       "         'why': 18,\n",
       "         'abuse': 2,\n",
       "         \"they're\": 6,\n",
       "         'loyal': 1,\n",
       "         'actually': 4,\n",
       "         'typing': 1,\n",
       "         'tweet': 7,\n",
       "         'take': 7,\n",
       "         'anymore..': 1,\n",
       "         'applicablehulog': 1,\n",
       "         'applicable': 3,\n",
       "         'knock': 2,\n",
       "         'd': 2,\n",
       "         'imagine': 3,\n",
       "         'wins': 1,\n",
       "         'Same': 3,\n",
       "         'Cue': 1,\n",
       "         'something': 3,\n",
       "         \"smile....I'll\": 1,\n",
       "         'waiting...:(': 1,\n",
       "         '.3': 10,\n",
       "         '.4': 7,\n",
       "         'these': 7,\n",
       "         'nosebleeds': 1,\n",
       "         'outta': 2,\n",
       "         'hands': 2,\n",
       "         'perfectly': 1,\n",
       "         'single': 1,\n",
       "         'Until': 1,\n",
       "         'couple': 2,\n",
       "         ':(KISSES': 1,\n",
       "         'TheFashionIcon': 1,\n",
       "         'Dude': 1,\n",
       "         'sleep': 7,\n",
       "         'fucking': 2,\n",
       "         'shit': 4,\n",
       "         'wont': 3,\n",
       "         'able': 2,\n",
       "         'stream': 4,\n",
       "         'sorry': 11,\n",
       "         'swapped': 5,\n",
       "         'cat': 6,\n",
       "         'dog': 6,\n",
       "         'upsetting': 6,\n",
       "         'system': 1,\n",
       "         'recognize': 1,\n",
       "         'spaces': 2,\n",
       "         'last': 8,\n",
       "         'names': 2,\n",
       "         '2nd': 2,\n",
       "         'unable': 1,\n",
       "         'forced': 1,\n",
       "         'unnecessary': 1,\n",
       "         'lines': 1,\n",
       "         'waiting': 1,\n",
       "         'Thank': 5,\n",
       "         'tons': 1,\n",
       "         'rocks.': 2,\n",
       "         'question': 2,\n",
       "         'astro': 2,\n",
       "         'It': 4,\n",
       "         'fault': 1,\n",
       "         'customs': 2,\n",
       "         'Argentina': 1,\n",
       "         'fill': 1,\n",
       "         'paperwork': 1,\n",
       "         'fixing': 1,\n",
       "         'choristers': 1,\n",
       "         'dress': 2,\n",
       "         'hem': 1,\n",
       "         'came': 1,\n",
       "         'undone': 1,\n",
       "         'by': 9,\n",
       "         'taping': 1,\n",
       "         'fabric': 1,\n",
       "         'tape': 1,\n",
       "         'put': 3,\n",
       "         'wrong': 4,\n",
       "         'even': 8,\n",
       "         'ruined': 3,\n",
       "         'Small': 1,\n",
       "         'fishie': 1,\n",
       "         'died': 1,\n",
       "         'nice': 6,\n",
       "         'outside': 2,\n",
       "         'stuck': 1,\n",
       "         'school': 11,\n",
       "         'EDM': 1,\n",
       "         'pleaseeeeeeeee': 1,\n",
       "         'mishutuuu': 1,\n",
       "         'Can': 3,\n",
       "         'julia': 1,\n",
       "         '??pleasee': 1,\n",
       "         'Bby': 1,\n",
       "         'emotion': 1,\n",
       "         'seriously': 1,\n",
       "         'Coldplay': 1,\n",
       "         'band': 1,\n",
       "         'Depeche': 1,\n",
       "         'Mode': 1,\n",
       "         'U2': 1,\n",
       "         'kept': 2,\n",
       "         'poor': 8,\n",
       "         'hate': 7,\n",
       "         'strong': 2,\n",
       "         'jfjfjkf': 1,\n",
       "         'NEED': 1,\n",
       "         'A': 9,\n",
       "         'UNICORN': 1,\n",
       "         'FRAPPUCCINO': 1,\n",
       "         'STAT.': 1,\n",
       "         'JUST': 1,\n",
       "         'FOUND': 1,\n",
       "         'OUT': 1,\n",
       "         'THEY': 1,\n",
       "         'ARE': 3,\n",
       "         'LIMITED': 1,\n",
       "         'TIMEE!': 1,\n",
       "         'much': 32,\n",
       "         'longer?': 1,\n",
       "         'hear': 1,\n",
       "         'this.....': 1,\n",
       "         \"won't.\": 1,\n",
       "         'phil': 1,\n",
       "         \"hasn't\": 6,\n",
       "         'seen': 1,\n",
       "         'Yuri': 1,\n",
       "         'here': 17,\n",
       "         \"didn't\": 8,\n",
       "         'second': 2,\n",
       "         'snsd': 1,\n",
       "         'missed': 3,\n",
       "         'campervan': 1,\n",
       "         'tickets': 2,\n",
       "         'expensive?': 1,\n",
       "         'Canberra': 1,\n",
       "         'land-locked': 1,\n",
       "         'capital.': 1,\n",
       "         'much?': 2,\n",
       "         'seem': 3,\n",
       "         'deathmatch': 2,\n",
       "         '.agata': 1,\n",
       "         'broke': 4,\n",
       "         'mail.': 1,\n",
       "         'read': 3,\n",
       "         'letter': 1,\n",
       "         'thank': 4,\n",
       "         'enough.': 1,\n",
       "         'best': 5,\n",
       "         'she': 6,\n",
       "         'is!': 1,\n",
       "         'HAHA': 1,\n",
       "         'look': 7,\n",
       "         'v': 1,\n",
       "         'dead': 1,\n",
       "         'Puta': 1,\n",
       "         \"isn't\": 4,\n",
       "         'enough': 4,\n",
       "         'pero': 1,\n",
       "         'padin': 1,\n",
       "         'mannn': 1,\n",
       "         \"m's\": 1,\n",
       "         'feeling': 4,\n",
       "         'early': 4,\n",
       "         'start': 3,\n",
       "         '1GB': 1,\n",
       "         'data': 1,\n",
       "         'per': 2,\n",
       "         'tonight!!': 1,\n",
       "         'told': 3,\n",
       "         'bugger': 1,\n",
       "         'hung': 1,\n",
       "         'up!': 1,\n",
       "         'They': 6,\n",
       "         'waned': 1,\n",
       "         'access': 2,\n",
       "         'pc.': 1,\n",
       "         'phoned': 1,\n",
       "         'someone': 9,\n",
       "         'Gran': 1,\n",
       "         'braces': 1,\n",
       "         'hurt': 1,\n",
       "         'Ohh': 1,\n",
       "         'welcome': 2,\n",
       "         'CLXSSlC': 1,\n",
       "         'chanyeol': 1,\n",
       "         'oppa!': 1,\n",
       "         'Or': 1,\n",
       "         'call': 8,\n",
       "         'richard?': 1,\n",
       "         'Kalau': 1,\n",
       "         'jadi': 1,\n",
       "         'sayang': 1,\n",
       "         'gimana?': 1,\n",
       "         'Claaaaaaaaaaaaasse': 1,\n",
       "         'What': 7,\n",
       "         'pity!': 1,\n",
       "         'Those': 1,\n",
       "         'beautiful!': 1,\n",
       "         'But': 9,\n",
       "         'answer!': 1,\n",
       "         'Sciatica.': 1,\n",
       "         'monumental': 1,\n",
       "         'pain': 3,\n",
       "         'arse.': 1,\n",
       "         'This': 9,\n",
       "         'escalated': 1,\n",
       "         'quickly': 1,\n",
       "         'aborting': 1,\n",
       "         'mission': 1,\n",
       "         'x': 4,\n",
       "         'tons.1': 1,\n",
       "         'No': 5,\n",
       "         'tonight!': 1,\n",
       "         'Throat': 1,\n",
       "         'killing': 1,\n",
       "         'too...I': 1,\n",
       "         \"won't\": 7,\n",
       "         'HGVs': 1,\n",
       "         'past': 2,\n",
       "         'our': 6,\n",
       "         'house': 2,\n",
       "         'though.': 2,\n",
       "         'looking': 4,\n",
       "         'building': 2,\n",
       "         'had': 15,\n",
       "         'initiall': 1,\n",
       "         \"Summer's\": 1,\n",
       "         \"school's\": 1,\n",
       "         'vocabulary': 1,\n",
       "         'We': 14,\n",
       "         'air.': 1,\n",
       "         'Please': 14,\n",
       "         \"Bae's\": 1,\n",
       "         'Wanna': 1,\n",
       "         'haircut': 1,\n",
       "         'place': 2,\n",
       "         'kind': 3,\n",
       "         'empty': 1,\n",
       "         'w/o': 2,\n",
       "         'youngjae': 1,\n",
       "         'at': 37,\n",
       "         'venue..': 1,\n",
       "         \"that's\": 10,\n",
       "         'true': 2,\n",
       "         'leave': 2,\n",
       "         'Yesterday': 1,\n",
       "         'felt': 2,\n",
       "         'friday': 1,\n",
       "         '[PLEASE': 3,\n",
       "         'RT]': 3,\n",
       "         \"he'll\": 4,\n",
       "         'buy': 7,\n",
       "         'blinking': 3,\n",
       "         'taehyung': 3,\n",
       "         'headband': 1,\n",
       "         '900': 6,\n",
       "         'retweets': 3,\n",
       "         'likes.': 3,\n",
       "         'help': 14,\n",
       "         ':(un': 1,\n",
       "         'yes': 5,\n",
       "         'Nice!': 1,\n",
       "         'Some': 1,\n",
       "         'there!': 1,\n",
       "         'Mostly': 1,\n",
       "         'black': 1,\n",
       "         'dresses': 1,\n",
       "         'which': 3,\n",
       "         'away': 2,\n",
       "         'June': 3,\n",
       "         'wedding': 2,\n",
       "         'Beyond': 1,\n",
       "         'Goodnight': 2,\n",
       "         'princess': 2,\n",
       "         'friends': 6,\n",
       "         '.5': 4,\n",
       "         'Something': 1,\n",
       "         'wrong.': 1,\n",
       "         'spending': 1,\n",
       "         'naked': 2,\n",
       "         'beach': 1,\n",
       "         'hot': 1,\n",
       "         'sunshine.': 1,\n",
       "         'working': 2,\n",
       "         'cold': 2,\n",
       "         \"King's\": 1,\n",
       "         'Lynn': 1,\n",
       "         'Punishment': 1,\n",
       "         \"JB's\": 1,\n",
       "         'team!': 1,\n",
       "         'Aw': 1,\n",
       "         'goodnight': 1,\n",
       "         'angel!': 1,\n",
       "         'tiame': 1,\n",
       "         'fun!!': 1,\n",
       "         \"Wonho's\": 1,\n",
       "         'already': 14,\n",
       "         'amount': 2,\n",
       "         'loads': 3,\n",
       "         'sections': 1,\n",
       "         'ride': 1,\n",
       "         'netherton': 1,\n",
       "         'Darby': 1,\n",
       "         'Q2': 1,\n",
       "         'MH': 1,\n",
       "         'healthcare': 1,\n",
       "         'professional.': 1,\n",
       "         'As': 4,\n",
       "         'scared': 5,\n",
       "         'death': 2,\n",
       "         'might': 2,\n",
       "         'situation': 1,\n",
       "         'Got': 1,\n",
       "         'msg!': 1,\n",
       "         'Oops': 1,\n",
       "         'Just': 6,\n",
       "         'chillin~': 1,\n",
       "         'bit': 4,\n",
       "         'quiet': 1,\n",
       "         'tough': 1,\n",
       "         'luck': 3,\n",
       "         'you??': 1,\n",
       "         'bet': 1,\n",
       "         \"media's\": 1,\n",
       "         'one-sided': 1,\n",
       "         'Tim': 1,\n",
       "         'Tams': 1,\n",
       "         'surprisingly': 1,\n",
       "         'alt-right': 1,\n",
       "         'roar': 1,\n",
       "         'extreme': 1,\n",
       "         'droll': 1,\n",
       "         'Fad': 1,\n",
       "         'hair': 7,\n",
       "         'crisp': 1,\n",
       "         'Going': 1,\n",
       "         'CA': 1,\n",
       "         'July': 1,\n",
       "         'reunion': 1,\n",
       "         'August': 1,\n",
       "         'road': 1,\n",
       "         'traffic': 1,\n",
       "         'signs': 1,\n",
       "         'section': 1,\n",
       "         'theory': 2,\n",
       "         'revision': 1,\n",
       "         'such': 6,\n",
       "         'myth': 1,\n",
       "         'pizza': 1,\n",
       "         'arrived': 1,\n",
       "         'mushrooms': 1,\n",
       "         'despite': 1,\n",
       "         'request.': 3,\n",
       "         'touch': 3,\n",
       "         'vi': 1,\n",
       "         'kabute': 1,\n",
       "         'things': 5,\n",
       "         \"i've\": 2,\n",
       "         'bought': 2,\n",
       "         'sweets': 1,\n",
       "         'Wish': 2,\n",
       "         'listen': 1,\n",
       "         'rain': 2,\n",
       "         'fellow': 1,\n",
       "         'Comm': 1,\n",
       "         'students': 1,\n",
       "         'suck-up...': 1,\n",
       "         'me?': 5,\n",
       "         'GO': 1,\n",
       "         'AWAY': 1,\n",
       "         'ally': 1,\n",
       "         'poem': 1,\n",
       "         'cute': 5,\n",
       "         'ehh': 1,\n",
       "         'DM': 5,\n",
       "         'beautiful': 5,\n",
       "         'ladies': 1,\n",
       "         'body': 2,\n",
       "         'confidence.': 1,\n",
       "         's': 1,\n",
       "         'italian': 1,\n",
       "         'easier': 2,\n",
       "         'than': 6,\n",
       "         'spanish': 1,\n",
       "         'difficult': 2,\n",
       "         'says': 3,\n",
       "         'him': 17,\n",
       "         'only': 18,\n",
       "         'been': 23,\n",
       "         '3': 11,\n",
       "         'nights': 3,\n",
       "         'mama': 1,\n",
       "         'province': 1,\n",
       "         'her': 13,\n",
       "         'cry': 3,\n",
       "         'got7': 1,\n",
       "         'continue': 2,\n",
       "         'lighting': 1,\n",
       "         'shitty': 1,\n",
       "         'f': 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter(text.split(' '))\n",
    "words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Чтобы заранее создать таблицу, узнаем количество уникальных слов<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'plans',\n",
       " 'okay.',\n",
       " 'liked',\n",
       " \"He's\",\n",
       " 'Braam.',\n",
       " 'absorbed',\n",
       " 'Man',\n",
       " 'ones',\n",
       " 'ask.',\n",
       " ')',\n",
       " 'me.',\n",
       " 'braces',\n",
       " 'fixing',\n",
       " 'dream',\n",
       " 'WAITED',\n",
       " 'housewives',\n",
       " 'students',\n",
       " 'BDAY',\n",
       " 'parents',\n",
       " 'eveand',\n",
       " 'Those',\n",
       " 'translator',\n",
       " 'busy',\n",
       " 'chopsuey',\n",
       " 'flavorful',\n",
       " '//',\n",
       " 'oppa!',\n",
       " 'reminds',\n",
       " 'Meredith',\n",
       " 'MORE',\n",
       " 'dye',\n",
       " '!!!!',\n",
       " 'daianeryoufato',\n",
       " 'gray',\n",
       " \"i'm\",\n",
       " 'freebet',\n",
       " 'loyal',\n",
       " 'Studio',\n",
       " 'Could',\n",
       " 'At',\n",
       " 'any',\n",
       " 'salons',\n",
       " 'valid?',\n",
       " 'cold.',\n",
       " 'italian',\n",
       " '+I',\n",
       " 'phonecase',\n",
       " 'bastard',\n",
       " 'You',\n",
       " 'blocked',\n",
       " 'Trying',\n",
       " 'that!',\n",
       " 'mate',\n",
       " 'haih',\n",
       " 'Someone',\n",
       " 'slight',\n",
       " 'froze',\n",
       " 'One',\n",
       " 'names',\n",
       " 'U2',\n",
       " 'netherton',\n",
       " 'Cutest',\n",
       " 'question',\n",
       " 'girl!',\n",
       " 'ending',\n",
       " 'completed',\n",
       " 'today..',\n",
       " \"child's\",\n",
       " 'sangat',\n",
       " 'faves',\n",
       " 'with',\n",
       " 'numbers',\n",
       " 'Tokyo',\n",
       " 'goodbye',\n",
       " 'maghapon',\n",
       " '(band)',\n",
       " 'live',\n",
       " 'seen',\n",
       " 'other',\n",
       " 'PRECIOUS',\n",
       " 'scenes.',\n",
       " \"Rand's\",\n",
       " 'strong',\n",
       " 'fun',\n",
       " 'sections',\n",
       " \"They're\",\n",
       " 'enough',\n",
       " 'isa',\n",
       " 'tumhari.',\n",
       " 'applicableg-iinot',\n",
       " 'as',\n",
       " 'grabe',\n",
       " 'lazy',\n",
       " 'WAITING',\n",
       " \"y'all\",\n",
       " 'robots',\n",
       " 'cheering',\n",
       " 'gambateh',\n",
       " 'tattoos',\n",
       " 'ca.3',\n",
       " 'Milk',\n",
       " 'A*dy',\n",
       " 'H',\n",
       " 'homework',\n",
       " 'Save',\n",
       " 'youngjae',\n",
       " 'campervan',\n",
       " 'checking',\n",
       " 'internet',\n",
       " 'shocking',\n",
       " 'Dont',\n",
       " 'absolutely',\n",
       " '10%',\n",
       " \"he'll\",\n",
       " \"Henry's\",\n",
       " 'sent',\n",
       " 'unfortunately',\n",
       " 'outsider',\n",
       " 'finish',\n",
       " 'so:(ButHedonism',\n",
       " 'falling',\n",
       " 'lighter',\n",
       " 'penny',\n",
       " 'tonight!!',\n",
       " 'forbid',\n",
       " 'Riverdale',\n",
       " 'Oops',\n",
       " 'actually',\n",
       " 'arrived',\n",
       " 'patches',\n",
       " 'gimana?',\n",
       " 'which',\n",
       " 'stayed',\n",
       " 'dog',\n",
       " 'per',\n",
       " 'suck-up...',\n",
       " 'waking',\n",
       " 'besh',\n",
       " 'noooooor',\n",
       " '7',\n",
       " 'THAT',\n",
       " 'sucks',\n",
       " 'Roc',\n",
       " \"fuckin'\",\n",
       " '2017',\n",
       " 'Hey',\n",
       " 'raid',\n",
       " 'youu',\n",
       " 'KASI',\n",
       " 'camera',\n",
       " 'see',\n",
       " 'uranus',\n",
       " 'dub',\n",
       " 'people',\n",
       " \"Don't\",\n",
       " 'provide',\n",
       " 'Aw',\n",
       " 'internship',\n",
       " \"can't\",\n",
       " 'shorthand',\n",
       " 'FML',\n",
       " 'Youre',\n",
       " '40k',\n",
       " 'VIP',\n",
       " \"Where's\",\n",
       " 'bodies.',\n",
       " 'Ride',\n",
       " 'browser',\n",
       " 'hard.',\n",
       " 'Biggest',\n",
       " 'Louis_Tomlinson',\n",
       " 'gotten',\n",
       " 'are',\n",
       " 'retard',\n",
       " 'says',\n",
       " 'thats',\n",
       " 'snsd.',\n",
       " 'Cleantha',\n",
       " 'Of',\n",
       " 'interesting.',\n",
       " 'sweet',\n",
       " 'signing',\n",
       " \"hasn't\",\n",
       " 'closing',\n",
       " 'be',\n",
       " 'stripes',\n",
       " 'pls?',\n",
       " 'earlier',\n",
       " 'shooting',\n",
       " 'if',\n",
       " 'semester',\n",
       " 'Then',\n",
       " 'college',\n",
       " 'enlisting',\n",
       " 'penge',\n",
       " 'coming.',\n",
       " 'tomorrow',\n",
       " 'out...',\n",
       " 'sitting',\n",
       " 'trophy',\n",
       " 'julia',\n",
       " 'last',\n",
       " 'Dear',\n",
       " 'came',\n",
       " 'part',\n",
       " 'Youngjae',\n",
       " 'here.',\n",
       " 'All',\n",
       " 'unable',\n",
       " 'YOUR',\n",
       " 'area.',\n",
       " 'caught',\n",
       " 'curls',\n",
       " 'yard',\n",
       " 'vote',\n",
       " \"i've\",\n",
       " 'rise',\n",
       " 'haircut',\n",
       " 'Ohh',\n",
       " 'callie',\n",
       " 'Kalau',\n",
       " ':(un.2',\n",
       " 'store',\n",
       " 'every',\n",
       " 'Hope',\n",
       " 'Joy',\n",
       " 'drinks',\n",
       " ':^)',\n",
       " 'hardwork',\n",
       " 'following',\n",
       " 'lost:',\n",
       " 'education',\n",
       " 'bullshit',\n",
       " 'ride',\n",
       " \"We've\",\n",
       " 'during',\n",
       " 'Baba',\n",
       " 'huhu',\n",
       " 'Miami',\n",
       " 'cant',\n",
       " 'adding',\n",
       " 'fr',\n",
       " 'despite',\n",
       " 'Money',\n",
       " 'holding',\n",
       " 'quickly',\n",
       " 'storm',\n",
       " 'ha',\n",
       " 'stronger',\n",
       " 'exposing',\n",
       " 'gym',\n",
       " 'god',\n",
       " 'pain',\n",
       " 'w/o',\n",
       " 'feels',\n",
       " ':',\n",
       " '.4',\n",
       " 'xDShame',\n",
       " '2000',\n",
       " 'news',\n",
       " 'myself',\n",
       " 'ass',\n",
       " 'support.',\n",
       " 'mager',\n",
       " 'Bday',\n",
       " 'sending',\n",
       " 'others',\n",
       " 'spoons',\n",
       " 'nice',\n",
       " 'ca.16',\n",
       " 'ikr.',\n",
       " '13!!!!',\n",
       " 'When',\n",
       " 'fame',\n",
       " 'resetting',\n",
       " 'doors',\n",
       " 'stream',\n",
       " 'heeeeey',\n",
       " 'dungeon',\n",
       " 'heart',\n",
       " 'beach',\n",
       " 'Roshan',\n",
       " '.2',\n",
       " 'manifesto',\n",
       " 'Goodmorning!!',\n",
       " 'ca.11',\n",
       " 'know',\n",
       " 'man..',\n",
       " 'stay',\n",
       " \"Wonho's\",\n",
       " 'Sad',\n",
       " 'winning',\n",
       " 'heck',\n",
       " 'YOU.',\n",
       " 'retweets',\n",
       " 'easier',\n",
       " 'attend',\n",
       " 'single',\n",
       " 'bi',\n",
       " '100',\n",
       " 'font',\n",
       " 'life',\n",
       " 'not.5',\n",
       " 'moment',\n",
       " 'commend',\n",
       " 'scary',\n",
       " 'waaaaay',\n",
       " 'endgame',\n",
       " 'mad',\n",
       " 'muh',\n",
       " '00:00:19',\n",
       " 'too',\n",
       " 'big',\n",
       " \"I'VE\",\n",
       " 'orientation',\n",
       " 'Whew!',\n",
       " 'Ouchhhhh',\n",
       " 'boy',\n",
       " 'ARTISTS',\n",
       " 'video',\n",
       " 'well.',\n",
       " 'decides',\n",
       " 'from',\n",
       " 'foot',\n",
       " 'hand',\n",
       " 'biggest',\n",
       " 'WOULD',\n",
       " 'use?',\n",
       " 'judge',\n",
       " ':v',\n",
       " 'Sucks!',\n",
       " 'changing',\n",
       " 'wished',\n",
       " 'least',\n",
       " 'jisung',\n",
       " 'salve',\n",
       " 'jenna',\n",
       " 'network!',\n",
       " 'times...',\n",
       " 'embarrass',\n",
       " 'caffeine',\n",
       " 'KATRIKA',\n",
       " 'RELATABLE',\n",
       " 'cellphone',\n",
       " 'before',\n",
       " 'morning',\n",
       " 'etc',\n",
       " 'ify',\n",
       " 'batbuffy.',\n",
       " 'base',\n",
       " 'make',\n",
       " 'league',\n",
       " 'egg',\n",
       " 'She',\n",
       " 'recognized',\n",
       " 'Faltan',\n",
       " 'dress',\n",
       " 'RIP',\n",
       " 'reaper',\n",
       " 'fuck',\n",
       " 'Astaga',\n",
       " 'bluebells',\n",
       " 'done',\n",
       " 'Her',\n",
       " 'dinneeeer',\n",
       " '-',\n",
       " 'Steel',\n",
       " 'mind',\n",
       " 'wink',\n",
       " 'metal.',\n",
       " 'agree.',\n",
       " 'hi',\n",
       " \"(can't\",\n",
       " 'buffalo',\n",
       " 'me...',\n",
       " 'NIGHT.',\n",
       " 'headband.1',\n",
       " 'Did',\n",
       " 'Call',\n",
       " 'later',\n",
       " 'sad',\n",
       " 'jadi',\n",
       " '10',\n",
       " '938',\n",
       " 'Robin',\n",
       " 'touch',\n",
       " 'Nice!',\n",
       " 'cyber',\n",
       " 'argument',\n",
       " 'jacket',\n",
       " ':(un.1',\n",
       " 'backup',\n",
       " 'naked',\n",
       " 'back',\n",
       " \"It's\",\n",
       " 'love',\n",
       " 'unnecessary',\n",
       " 'Racing',\n",
       " 'reunite',\n",
       " 'knock',\n",
       " 'yummy',\n",
       " 'AC)',\n",
       " '11',\n",
       " 'hem',\n",
       " ':/',\n",
       " 'numb',\n",
       " \"harry's\",\n",
       " 'Sooooo',\n",
       " 'Super',\n",
       " 'sampaikan',\n",
       " 'abuse',\n",
       " 'up',\n",
       " 'finals',\n",
       " 'Sir',\n",
       " 'WANT',\n",
       " 'eye',\n",
       " 'kind',\n",
       " 'roommates',\n",
       " 'Easter',\n",
       " 'keen',\n",
       " '.',\n",
       " '.12',\n",
       " 'reunion',\n",
       " 'dorky',\n",
       " 'confidence.',\n",
       " 'secs.',\n",
       " 'farro',\n",
       " 'Nani',\n",
       " 'sila',\n",
       " 'uu',\n",
       " 'experience',\n",
       " 'aromaterapi',\n",
       " 'complaining',\n",
       " 'thirst',\n",
       " 'jihoon',\n",
       " 'FUN',\n",
       " 'possible!',\n",
       " 'surprisingly',\n",
       " 'capital.',\n",
       " 'GONNA',\n",
       " 'Am',\n",
       " 'EVERY',\n",
       " 'car',\n",
       " 'guys',\n",
       " 'list',\n",
       " 'bubbyyyyyyy',\n",
       " '(4)',\n",
       " 'why',\n",
       " '1K',\n",
       " 'somethings',\n",
       " 'nothing',\n",
       " 'today!',\n",
       " 'youd',\n",
       " \"Powerpoint'te\",\n",
       " 'yoyoure',\n",
       " 'Aww',\n",
       " 'can',\n",
       " 'hawhaw',\n",
       " 'Left',\n",
       " '.8',\n",
       " 'PLS',\n",
       " \"i'll\",\n",
       " 'house',\n",
       " 'Shit',\n",
       " 'streaks',\n",
       " 'reason',\n",
       " 'ginger',\n",
       " 'wait',\n",
       " 'ME',\n",
       " 'laptop',\n",
       " 'again',\n",
       " 'ruined',\n",
       " 'tour',\n",
       " '!',\n",
       " 'down!',\n",
       " 'sort',\n",
       " 'tomorrow!!',\n",
       " 'Canberra',\n",
       " 'CAN',\n",
       " 'unicorn',\n",
       " 'wasnt',\n",
       " 'Nooo',\n",
       " 'Sunnyside',\n",
       " 'arms',\n",
       " 'Vimeo',\n",
       " 'for..',\n",
       " 'waffle',\n",
       " 'cont1.1',\n",
       " 'meant',\n",
       " 'small',\n",
       " '2NE1',\n",
       " 'ca.15',\n",
       " 'nosebleeds',\n",
       " 'lamp',\n",
       " 'mobbing',\n",
       " 'mane',\n",
       " 'headband.2',\n",
       " \"Daniel's\",\n",
       " 'purple',\n",
       " 'dealer',\n",
       " 'find',\n",
       " 'everyday',\n",
       " 'OS',\n",
       " 'notification',\n",
       " 'something',\n",
       " 'v',\n",
       " 'plss',\n",
       " 'Kanji',\n",
       " 'late?',\n",
       " 'Twp',\n",
       " 'LIKE',\n",
       " 'fryer',\n",
       " 'upsetting',\n",
       " 'matter',\n",
       " 'buried',\n",
       " 'breaks',\n",
       " 'women',\n",
       " 'meds',\n",
       " 'wronged',\n",
       " 'them',\n",
       " \"you'll\",\n",
       " 'crashes',\n",
       " 'McConnell',\n",
       " 'current',\n",
       " 'dame',\n",
       " 'Spend',\n",
       " 'Town',\n",
       " 'seller',\n",
       " 'abroad',\n",
       " 'MEANIE',\n",
       " 'health',\n",
       " 'cheer',\n",
       " 'pu',\n",
       " 'damn',\n",
       " 'quit',\n",
       " 'syouggest',\n",
       " 'ikr!!',\n",
       " 'win',\n",
       " 'deleted',\n",
       " 'lots',\n",
       " 'province',\n",
       " 'sometimes',\n",
       " 'Notice',\n",
       " 'did',\n",
       " 'mats',\n",
       " 'spicy',\n",
       " 'Nope',\n",
       " 'raining',\n",
       " 'happening?',\n",
       " 'Same.',\n",
       " 'droll',\n",
       " 'Sakho',\n",
       " 'Missing',\n",
       " 'iand',\n",
       " 'Coeurl',\n",
       " 'getting',\n",
       " 'unfortunate',\n",
       " 'energy',\n",
       " 'accepted',\n",
       " 'tonight!',\n",
       " 'still..',\n",
       " 'gigs',\n",
       " 'were',\n",
       " 'aando',\n",
       " 'mountain',\n",
       " '2hrs',\n",
       " 'HUNGRY',\n",
       " 'stuff',\n",
       " 'country',\n",
       " 'Don',\n",
       " 'Yet',\n",
       " 'crash',\n",
       " 'chatting',\n",
       " 'messages',\n",
       " 'ourselves',\n",
       " 'flowercrown',\n",
       " 'TheFashionIcon',\n",
       " 'up!',\n",
       " 'draw',\n",
       " 'outta',\n",
       " 'today-',\n",
       " \"we'll\",\n",
       " 'meeting',\n",
       " 'taxes)',\n",
       " 'Errr',\n",
       " 'aegyo',\n",
       " 'youre',\n",
       " 'Hitches',\n",
       " 'ignore',\n",
       " 'sleepy',\n",
       " '(night',\n",
       " 'depend',\n",
       " 'hottest',\n",
       " 'unfollowed',\n",
       " 'Snapchat',\n",
       " 'follow',\n",
       " 'toy',\n",
       " 'bb8',\n",
       " 'changed?',\n",
       " 'hurts',\n",
       " 'sweets',\n",
       " 'capitalise',\n",
       " 'please?',\n",
       " 'should',\n",
       " 'flawed',\n",
       " 'happened',\n",
       " 'struggle',\n",
       " 'Used',\n",
       " 'But',\n",
       " 'personal',\n",
       " 'excited',\n",
       " 'everyone',\n",
       " 'revision',\n",
       " 'velvet',\n",
       " 'Bruins',\n",
       " 'Celtics',\n",
       " 'read',\n",
       " 'Looks',\n",
       " 'true',\n",
       " 'favorites',\n",
       " 'hannah',\n",
       " 'yous?',\n",
       " 'A',\n",
       " 'losing',\n",
       " \"they'll\",\n",
       " 'when?',\n",
       " 'away',\n",
       " 'princess',\n",
       " 'never',\n",
       " 'tulips',\n",
       " 'waned',\n",
       " 'schematic',\n",
       " 'own.',\n",
       " 'so?',\n",
       " 'Ngomel',\n",
       " 'late',\n",
       " 'yoongi',\n",
       " 'yeo',\n",
       " 'hehehe.',\n",
       " 'chance',\n",
       " 'Beyond',\n",
       " 'variable',\n",
       " 'would',\n",
       " 'starbucks',\n",
       " 'aw',\n",
       " \"there'll\",\n",
       " 'Quebec',\n",
       " 'HAHAHAH',\n",
       " 'sa',\n",
       " 'High',\n",
       " 'say',\n",
       " 'scrobbles',\n",
       " 'prince',\n",
       " 'Laugharne',\n",
       " 'loves',\n",
       " 'hehe',\n",
       " 'Why',\n",
       " 'mafia',\n",
       " 'ready',\n",
       " 'Leyland',\n",
       " 'emotional',\n",
       " 'Makes',\n",
       " 'oh',\n",
       " 'tickets',\n",
       " 'Boys',\n",
       " 'seems',\n",
       " 'moodbooster',\n",
       " 'close',\n",
       " 'extreme',\n",
       " '.14',\n",
       " 'birthday',\n",
       " 'decide',\n",
       " 'days?',\n",
       " 'appropriate',\n",
       " 'borrow',\n",
       " 'give',\n",
       " 'Darby',\n",
       " 'legitimate',\n",
       " 'you!!',\n",
       " 'Claaaaaaaaaaaaasse',\n",
       " 'debyout',\n",
       " 'followers',\n",
       " '3',\n",
       " 'us.',\n",
       " 'ca.2',\n",
       " 'For',\n",
       " 'Wht',\n",
       " \"couldn't\",\n",
       " 'supports',\n",
       " 'synths',\n",
       " 'hates',\n",
       " 'Taiwan!',\n",
       " 'Scout',\n",
       " 'mission',\n",
       " 'senior',\n",
       " 'weekends',\n",
       " 'giveaways',\n",
       " 'Alea',\n",
       " 'retweeting',\n",
       " 'Weare',\n",
       " '4:17',\n",
       " 'rest.',\n",
       " 'try',\n",
       " 'failed',\n",
       " 'pretty',\n",
       " 'cosmic',\n",
       " 'Nick?',\n",
       " 'Gran',\n",
       " 'chair',\n",
       " 'year',\n",
       " 'waffles',\n",
       " 'heard',\n",
       " 'sound',\n",
       " 'possee',\n",
       " 'more',\n",
       " 'taken',\n",
       " 'warmest',\n",
       " 'void',\n",
       " '=(',\n",
       " 'YOU',\n",
       " 'time..',\n",
       " 'Goodnight',\n",
       " 'miss',\n",
       " 'noodles',\n",
       " 'plot',\n",
       " 'eunji',\n",
       " 'haha',\n",
       " 'kept',\n",
       " 'CGa',\n",
       " 'night',\n",
       " 'promoting',\n",
       " 'sunshine',\n",
       " 'inbut',\n",
       " 'show',\n",
       " 'issues',\n",
       " 'THIS',\n",
       " 'members',\n",
       " 'there?',\n",
       " 'Miss',\n",
       " 'monumental',\n",
       " 'sex',\n",
       " 'chat',\n",
       " 'hole',\n",
       " 'Before',\n",
       " 'not.8',\n",
       " 'yeah',\n",
       " 'padin',\n",
       " 'hours',\n",
       " 'because',\n",
       " 'cad',\n",
       " 'ticket',\n",
       " 'not.7',\n",
       " \"it's\",\n",
       " 'Feel',\n",
       " 'congratulations',\n",
       " 'well',\n",
       " 'pity!',\n",
       " \"Eremina's\",\n",
       " 'massaging',\n",
       " 'hello',\n",
       " 'Autograph',\n",
       " 'done????',\n",
       " 'Hmm',\n",
       " 'ever!',\n",
       " 'Streaming',\n",
       " 'brush',\n",
       " \"camila's\",\n",
       " 'river',\n",
       " 'seem',\n",
       " 'wish',\n",
       " 'app',\n",
       " 'attack',\n",
       " 'tomorrow.',\n",
       " 'TAKE',\n",
       " 'turtleneck',\n",
       " 'Rantoul',\n",
       " 'hort',\n",
       " 'giant',\n",
       " 'rip',\n",
       " 'super',\n",
       " 'theoretically',\n",
       " 'lonely',\n",
       " 'loads',\n",
       " 'fucking',\n",
       " 'killing',\n",
       " 'full',\n",
       " 'KNOW',\n",
       " 'issue',\n",
       " 'pizza',\n",
       " 'foods',\n",
       " 'ware',\n",
       " \"he'd\",\n",
       " 'our',\n",
       " 'believe',\n",
       " 'Thats',\n",
       " 'zoos',\n",
       " 'shiiiiid',\n",
       " 'direction',\n",
       " 'rusty',\n",
       " 's',\n",
       " 'IT',\n",
       " 'Haay',\n",
       " 'Molly',\n",
       " 'lies',\n",
       " 'woul',\n",
       " 'WITH',\n",
       " 'who',\n",
       " 'needs',\n",
       " 'great',\n",
       " 'turn',\n",
       " 'normally',\n",
       " \"wouldn't\",\n",
       " 'confining',\n",
       " 'smoke',\n",
       " 'accent',\n",
       " 'FOUND',\n",
       " 'paper',\n",
       " 'quite',\n",
       " 'home',\n",
       " 'LOL',\n",
       " 'TO',\n",
       " 'fish',\n",
       " 'reading',\n",
       " 'NOTICING',\n",
       " 'career.',\n",
       " 'memoriam',\n",
       " 'phil',\n",
       " 'cried',\n",
       " 'graceful',\n",
       " 'storage',\n",
       " 'commissi',\n",
       " \":(Today's\",\n",
       " 'GO',\n",
       " 'hyped',\n",
       " 'shows',\n",
       " 'sooner!!',\n",
       " 'Crap.',\n",
       " 'center',\n",
       " 'holidays',\n",
       " 'Every',\n",
       " 'goinghe',\n",
       " 'Morrison',\n",
       " '1',\n",
       " \":'((\",\n",
       " 'hung',\n",
       " 'had',\n",
       " 'delicious',\n",
       " 'HAVE',\n",
       " 'lng',\n",
       " 'noOoooooo',\n",
       " '5/6',\n",
       " 'HAHAH',\n",
       " 'expected....',\n",
       " 'baby!',\n",
       " \"'only\",\n",
       " 'Lynn',\n",
       " 'blast',\n",
       " 'Girl',\n",
       " '*hugs*',\n",
       " 'completely',\n",
       " 'spotify',\n",
       " 'park',\n",
       " 'makes',\n",
       " 'feelings',\n",
       " 'Sandton',\n",
       " 'fire',\n",
       " 'mental',\n",
       " 'dollar?',\n",
       " 'mi',\n",
       " \"we're\",\n",
       " 'milly',\n",
       " 'silence',\n",
       " 'pressed',\n",
       " 'deliver',\n",
       " 'jyoustinbieber',\n",
       " 'TIMEE!',\n",
       " 'run',\n",
       " 'unhappy',\n",
       " 'tweets',\n",
       " 'cute',\n",
       " 'lonely.',\n",
       " 'xD',\n",
       " 'Zac',\n",
       " 'Stare',\n",
       " '2010',\n",
       " 'Birthday',\n",
       " 'switched',\n",
       " 'mess.',\n",
       " 'reaching',\n",
       " 'meandu',\n",
       " 'pull',\n",
       " 'selling',\n",
       " 'SHIT!',\n",
       " 'Adore',\n",
       " 'played',\n",
       " 'Work',\n",
       " 'London',\n",
       " 'allow',\n",
       " \"isn't\",\n",
       " 'not',\n",
       " 'crusher',\n",
       " 'he',\n",
       " 'issue?',\n",
       " 'HGVs',\n",
       " 'largely',\n",
       " 'kuss',\n",
       " 'u?',\n",
       " 'eue',\n",
       " 'how',\n",
       " 'comes',\n",
       " 'may',\n",
       " \"you're\",\n",
       " 'week',\n",
       " 'know..',\n",
       " 'Jongin',\n",
       " 'camp',\n",
       " 'spaces',\n",
       " 'theres',\n",
       " 'vocabulary',\n",
       " 'pretended',\n",
       " 'Coldplay',\n",
       " '20',\n",
       " 'cereal',\n",
       " 'GOOD',\n",
       " 'turned',\n",
       " 'manja',\n",
       " 'kandowiandg',\n",
       " 'honey',\n",
       " 'really',\n",
       " 'japanese',\n",
       " 'richard?',\n",
       " 'cramping',\n",
       " 'intervention',\n",
       " 'basketball',\n",
       " 'lovely',\n",
       " 'next',\n",
       " 'due',\n",
       " 'display',\n",
       " 'whether',\n",
       " 'WHOLE',\n",
       " 'ca.6',\n",
       " 'died',\n",
       " 'head',\n",
       " 'Annette',\n",
       " 'lately?',\n",
       " 'cost',\n",
       " 'midnightreminds',\n",
       " 'number',\n",
       " 'alternate',\n",
       " 'obvious',\n",
       " 'exactly',\n",
       " 'her',\n",
       " 'colorful',\n",
       " 'FAMOUS',\n",
       " 'Aseek',\n",
       " 'iOS',\n",
       " 'do',\n",
       " 'sign',\n",
       " 'summer',\n",
       " 'social',\n",
       " 'light',\n",
       " 'Mine',\n",
       " 'jittery',\n",
       " 'songs',\n",
       " 'headphones',\n",
       " 'glasses',\n",
       " 'point',\n",
       " 'children',\n",
       " 'crocodile',\n",
       " 'evil',\n",
       " 'PL',\n",
       " 'trop',\n",
       " 'HIM',\n",
       " 'gabbie',\n",
       " 'Happy',\n",
       " 'slow',\n",
       " 'Men',\n",
       " 'Golly',\n",
       " 'it)can',\n",
       " 'calendars',\n",
       " 'April.',\n",
       " 'maps',\n",
       " 'Down',\n",
       " 'venue..',\n",
       " 'sailor',\n",
       " '18:40',\n",
       " 'serious',\n",
       " \"m's\",\n",
       " 'song',\n",
       " 'this.....',\n",
       " 'enough.',\n",
       " 'handball',\n",
       " 'damit',\n",
       " 'local',\n",
       " '4:30',\n",
       " 'alt-right',\n",
       " 'loser.',\n",
       " 'talking',\n",
       " 'Cinemax',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_words = set(words.keys())\n",
    "unic_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>В таблице для обучения понадобятся такие поля как:<h4>\n",
    "<h4>Существование слова в словаре нигативном, нейтральном и позитивном<h4>\n",
    "<h4>Сколько раз это слово встречается в наборе данных негативном, нейтральном и позитивном и общее количество раз<h4>\n",
    "<h4>TFIDF для негативного, нейтрального и позитивного наборов<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_exist_index = 0\n",
    "neut_exist_index = 1\n",
    "pos_exist_index = 2\n",
    "neg_count_index = 3\n",
    "neut_count_index = 4\n",
    "pos_count_index = 5\n",
    "word_count_index = 6\n",
    "neg_tfidf_index = 7\n",
    "neut_tfidf_index = 8\n",
    "pos_tfidf_index = 9\n",
    "\n",
    "neg_tokens = words\n",
    "neut_tokens = dict()\n",
    "pos_tokens = dict()\n",
    "df = np.zeros((len(unic_words), 10))\n",
    "for i, word in enumerate(unic_words):\n",
    "    if word in neg_tokens.keys():\n",
    "        df[i,neg_exist_index] = 1\n",
    "        df[i,neg_count_index] = neg_tokens[word]\n",
    "    if word in neut_tokens.keys():\n",
    "        df[i,neut_exist_index] = 1\n",
    "        df[i,neut_count_index] = neut_tokens[word]\n",
    "    if word in pos_tokens.keys():\n",
    "        df[i,pos_exist_index] = 1\n",
    "        df[i,pos_count_index] = pos_tokens[word]\n",
    "\n",
    "df[:,word_count_index] = df[:,neg_count_index] + df[:,neut_count_index] + df[:,pos_count_index]\n",
    "df[:,neg_tfidf_index] = df[:,neg_count_index] / df[:,word_count_index]\n",
    "df[:,neut_tfidf_index] = df[:,neut_count_index] / df[:,word_count_index]\n",
    "df[:,pos_tfidf_index] = df[:,pos_count_index] / df[:,word_count_index]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative counts</th>\n",
       "      <th>Neutral counts</th>\n",
       "      <th>Positive counts</th>\n",
       "      <th>Word counts</th>\n",
       "      <th>Negative TFIDF</th>\n",
       "      <th>Neutral TFIDF</th>\n",
       "      <th>Positive TFIDF</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cooperative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>groupmates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>friend?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3067 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Negative  Neutral  Positive  Negative counts  Neutral counts  \\\n",
       "0          1.0      0.0       0.0           1367.0             0.0   \n",
       "1          1.0      0.0       0.0              3.0             0.0   \n",
       "2          1.0      0.0       0.0              1.0             0.0   \n",
       "3          1.0      0.0       0.0              3.0             0.0   \n",
       "4          1.0      0.0       0.0              1.0             0.0   \n",
       "...        ...      ...       ...              ...             ...   \n",
       "3062       1.0      0.0       0.0              1.0             0.0   \n",
       "3063       1.0      0.0       0.0              4.0             0.0   \n",
       "3064       1.0      0.0       0.0              1.0             0.0   \n",
       "3065       1.0      0.0       0.0              1.0             0.0   \n",
       "3066       1.0      0.0       0.0              4.0             0.0   \n",
       "\n",
       "      Positive counts  Word counts  Negative TFIDF  Neutral TFIDF  \\\n",
       "0                 0.0       1367.0             1.0            0.0   \n",
       "1                 0.0          3.0             1.0            0.0   \n",
       "2                 0.0          1.0             1.0            0.0   \n",
       "3                 0.0          3.0             1.0            0.0   \n",
       "4                 0.0          1.0             1.0            0.0   \n",
       "...               ...          ...             ...            ...   \n",
       "3062              0.0          1.0             1.0            0.0   \n",
       "3063              0.0          4.0             1.0            0.0   \n",
       "3064              0.0          1.0             1.0            0.0   \n",
       "3065              0.0          1.0             1.0            0.0   \n",
       "3066              0.0          4.0             1.0            0.0   \n",
       "\n",
       "      Positive TFIDF         word  \n",
       "0                0.0          How  \n",
       "1                0.0      unhappy  \n",
       "2                0.0               \n",
       "3                0.0         some  \n",
       "4                0.0         dogs  \n",
       "...              ...          ...  \n",
       "3062             0.0       talaga  \n",
       "3063             0.0  cooperative  \n",
       "3064             0.0   groupmates  \n",
       "3065             0.0        hindi  \n",
       "3066             0.0      friend?  \n",
       "\n",
       "[3067 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metod_df = pd.DataFrame(df, columns=[\n",
    "    'Negative', 'Neutral', 'Positive',\n",
    "    'Negative counts', 'Neutral counts', 'Positive counts', 'Word counts',\n",
    "    'Negative TFIDF', 'Neutral TFIDF', 'Positive TFIDF'])\n",
    "metod_df[\"word\"] = words\n",
    "metod_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Функции будут иметь следующий вид:<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metod_file_to_df(file_name):\n",
    "    neg_fn, neut_fn, pos_fn = file_name\n",
    "\n",
    "    neg_df = pd.read_csv(neg_fn).T.reset_index()\n",
    "    neut_df = pd.read_csv(neut_fn).T.reset_index()\n",
    "    pos_df = pd.read_csv(pos_fn).T.reset_index()\n",
    "    \n",
    "    neg_text = \" \".join([tweet[0] for tweet in neg_df.values.tolist()])\n",
    "    neut_text = \" \".join([tweet[0] for tweet in neut_df.values.tolist()])\n",
    "    pos_text = \" \".join([tweet[0] for tweet in pos_df.values.tolist()])\n",
    "\n",
    "    neg_words = Counter(\"metod\")\n",
    "    neut_words = Counter(\"metod\")\n",
    "    pos_words = Counter(\"metod\")\n",
    "    \n",
    "    unic_words = list(set(neg_words.keys()) | set(neut_words.keys()) | set(pos_words.keys()))\n",
    "\n",
    "    neg_exist_index = 0\n",
    "    neut_exist_index = 1\n",
    "    pos_exist_index = 2\n",
    "    neg_count_index = 3\n",
    "    neut_count_index = 4\n",
    "    pos_count_index = 5\n",
    "    word_count_index = 6\n",
    "    neg_tfidf_index = 7\n",
    "    neut_tfidf_index = 8\n",
    "    pos_tfidf_index = 9\n",
    "\n",
    "    df = np.zeros((len(unic_words), 10))\n",
    "    for i, word in enumerate(unic_words):\n",
    "        if word in neg_words.keys():\n",
    "            df[i,neg_exist_index] = 1\n",
    "            df[i,neg_count_index] = neg_words[word]\n",
    "        if word in neut_words.keys():\n",
    "            df[i,neut_exist_index] = 1\n",
    "            df[i,neut_count_index] = neut_words[word]\n",
    "        if word in pos_words.keys():\n",
    "            df[i,pos_exist_index] = 1\n",
    "            df[i,pos_count_index] = pos_words[word]\n",
    "\n",
    "    df[:,word_count_index] = df[:,neg_count_index] + df[:,neut_count_index] + df[:,pos_count_index]\n",
    "    df[:,neg_tfidf_index] = df[:,neg_count_index] / df[:,word_count_index]\n",
    "    df[:,neut_tfidf_index] = df[:,neut_count_index] / df[:,word_count_index]\n",
    "    df[:,pos_tfidf_index] = df[:,pos_count_index] / df[:,word_count_index]\n",
    "\n",
    "    metod_df = pd.DataFrame(df, columns=[\n",
    "        'Negative', 'Neutral', 'Positive',\n",
    "        'Negative counts', 'Neutral counts', 'Positive counts', 'Word counts',\n",
    "        'Negative TFIDF', 'Neutral TFIDF', 'Positive TFIDF'])\n",
    "    metod_df[\"word\"] = unic_words\n",
    "    return metod_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Параметры для моделей<h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Преобразуем слова в векторы<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = Word2Vec(sentences=[unic_words], min_count=1)\n",
    "w2v.wv.vector_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>К сожелению, векторизация слов из набора данных занимает много времени, поэтому в дальнейшем будем использовать множество уникальных слов<h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Создадим входной параметр<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.14395749e-04, -4.51956381e-04, -9.80680343e-03, ...,\n",
       "        -3.42480652e-03, -2.13523838e-03, -8.05156026e-03],\n",
       "       [-4.07405617e-03, -2.87406310e-03, -9.01711232e-04, ...,\n",
       "         9.88634955e-03, -7.33754411e-03,  7.13394862e-03],\n",
       "       [ 3.48888640e-03, -2.25079129e-03,  7.54582090e-03, ...,\n",
       "        -8.02841224e-03, -3.21169826e-03, -6.48772018e-03],\n",
       "       ...,\n",
       "       [-9.56930034e-03, -2.91930302e-03, -2.54906132e-03, ...,\n",
       "        -3.61720286e-03, -3.46823712e-04, -3.11590661e-03],\n",
       "       [-6.60704263e-03, -3.79024306e-03, -7.24422978e-03, ...,\n",
       "        -5.63160796e-03, -9.69625078e-03, -4.85439785e-04],\n",
       "       [ 4.24624095e-03,  1.70569832e-03, -4.52962331e-03, ...,\n",
       "         4.29505436e-03,  8.74073157e-05, -4.25187312e-03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(metod_df.word), w2v.wv.vector_size))\n",
    "for i, word in enumerate(metod_df.word):\n",
    "    X[i,:w2v.wv.vector_size] = w2v.wv[word]\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Создадим выходной параметр<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1.0\n",
       "1      -1.0\n",
       "2      -1.0\n",
       "3      -1.0\n",
       "4      -1.0\n",
       "       ... \n",
       "3062   -1.0\n",
       "3063   -1.0\n",
       "3064   -1.0\n",
       "3065   -1.0\n",
       "3066   -1.0\n",
       "Length: 3067, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = (-metod_df['Negative'] + metod_df['Positive']) * 0.5 **metod_df['Neutral']\n",
    "Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Разделим наши праметры на тренировочные и тестовые<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7998043690903163, 0.20019563090968373)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n",
    "train_X.shape[0] / X.shape[0], test_X.shape[0] / X.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Найдем модель с наилучшим гиперпараметром<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/val/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/val/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "4 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/val/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/val/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1554, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: -1.0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/val/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='saga')\n",
    "train_Y[2000] = 0\n",
    "param_grid = {\n",
    "    'C': np.arange(1, 5)\n",
    "}\n",
    "\n",
    "search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "\n",
    "search.fit(train_X, train_Y)\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Обучим модель и узнаем её точность на тестовой выборке<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=search.best_params_['C'])\n",
    "clf.fit(train_X, train_Y)\n",
    "pred_Y = clf.predict(test_X)\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Объединим все действия в одну функцию<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection_exist_word(metod_df, unic_words):\n",
    "    \n",
    "    w2v = Word2Vec(sentences=[unic_words], min_count=1)\n",
    "\n",
    "    X = np.zeros((len(metod_df.word), w2v.wv.vector_size))\n",
    "    for i, word in enumerate(metod_df.word):\n",
    "        X[i,:w2v.wv.vector_size] = w2v.wv[word]\n",
    "    Y = pd.cut((-metod_df['Negative'] + metod_df['Positive']) * 0.5 **metod_df['Neutral'], bins=[-2, -0.33, 0.33,2], labels=[-1, 0, 1])\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = LogisticRegression(solver='saga')\n",
    "    param_grid = {\n",
    "        'C': np.arange(1, 5)\n",
    "    }\n",
    "\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "    search.fit(train_X, train_Y)\n",
    "    clf = LogisticRegression(C=search.best_params_['C'])\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred_Y = clf.predict(test_X)\n",
    "    return accuracy_score(test_Y, pred_Y)\n",
    "\n",
    "def model_selection_count_word(metod_df, unic_words):\n",
    "    \n",
    "    w2v = Word2Vec(sentences=[unic_words], min_count=1)\n",
    "\n",
    "    X = np.zeros((len(metod_df.word), w2v.wv.vector_size + 3))\n",
    "    for i, word in enumerate(metod_df.word):\n",
    "        X[i,:w2v.wv.vector_size] = w2v.wv[word]\n",
    "    X[:,w2v.wv.vector_size] = metod_df['Negative counts']\n",
    "    X[:,w2v.wv.vector_size + 1] = metod_df['Neutral counts']\n",
    "    X[:,w2v.wv.vector_size + 2] = metod_df['Positive counts']\n",
    "    Y = pd.cut((-metod_df['Negative'] + metod_df['Positive']) * 0.5 **metod_df['Neutral'], bins=[-2, -0.33, 0.33,2], labels=[-1, 0, 1])\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = LogisticRegression(solver='saga')\n",
    "    param_grid = {\n",
    "        'C': np.arange(1, 5)\n",
    "    }\n",
    "\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "    search.fit(train_X, train_Y)\n",
    "    clf = LogisticRegression(C=search.best_params_['C'])\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred_Y = clf.predict(test_X)\n",
    "    return accuracy_score(test_Y, pred_Y)\n",
    "\n",
    "def model_selection_tfidf(metod_df, unic_words):\n",
    "    \n",
    "    w2v = Word2Vec(sentences=[unic_words], min_count=1)\n",
    "\n",
    "    X = np.zeros((len(metod_df.word), w2v.wv.vector_size))\n",
    "    for i, word in enumerate(metod_df.word):\n",
    "        X[i,:w2v.wv.vector_size] = w2v.wv[word]\n",
    "    Y = pd.cut((-metod_df['Negative TFIDF'] + metod_df['Positive TFIDF']) * 0.5 **metod_df['Neutral TFIDF'], bins=[-2, -0.33, 0.33,2], labels=[-1, 0, 1])\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = LogisticRegression(solver='saga')\n",
    "    param_grid = {\n",
    "        'C': np.arange(1, 5)\n",
    "    }\n",
    "\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "    search.fit(train_X, train_Y)\n",
    "    clf = LogisticRegression(C=search.best_params_['C'])\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred_Y = clf.predict(test_X)\n",
    "    return accuracy_score(test_Y, pred_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
